System Design

Types of Requirements
	-	Features of the System
		-	Functional Requirements
	-	Quality Attributes
		-	Non-Functional Requirements
	-	System Constraints
		-	Limitations and boundaries.

(1)Functional Requirements
	-	More powerful way of gathering requirements:
		-	(1)use cases
			-	Situation/Scenario in which our system is used.
		-	(2)user flows
			-	A Step by Step/ graphical representation of each use case.
	-	Requirement Gathering Steps
		-	(1)Identify all the actors/users in the system.
		-	(2)Capture and describe all possible use-cases/scenarios.
		-	(3)User flow - Expand each use case through flow of events.

		Eg: HitchHiking Service - Actors
			-	Allow people to join drivers on a route, who are willing to take passengers for a fee.
				-	Actors
					-	Driver
					-	Rider
			HitchHiking Service - Rider Use Cases
				-	Rider first time registration
				-	Driver registration
				-	Rider login
				-	Driver login
				-	Successful match and ride
				-	UnSuccessful ride
	-	For Use cases we can use Sequence Diagrams
		-	Sequence Diagram - Diagram that represents interactions between actors and objects.
			-	It can be done by using UML(Unified Modeling Language)

(2)Non-Functionl Requirements
	-	Quality attributes are non-functional requirements
	-	The describe
		-	The qualities of functional requirements.
		-	The overall properties of the system.
	-	Provides a QUALITY MEASURE on how well a system performs on a PARTICULAR DIMENSION.
	-	Quality Attribute Example:
		-	Response time within 100 milliseconds
		-	The online store must be available at least 99.9% of the time.
		-	Development team can deploy a new version of the online store atleast twice a week.

	-	Quality Attributes considerations
		-	Quality attributes needs to be:
			-	(1) Measurable and Testable
				-	If we cannot prove that our system satisfied the required quality attributes we don't know if our system performs WELL or POORLY.
					-	Eg: When the user clicks a button then resoponse should be sent QUICKLY. here quickly is unmeasurable.
			-	(2)TradeOffs
				-	No single software architecture can provide all the quality attributes.
				-	Certain quality attributes contradict each other. For eg: login with 1 ms, but more security means more response time.
				-	Some quality attributes are very hard/impossible to achieve.
				-	Right tradeoff should be taken.
			-	(3)Feasibility
				-	System should meet requirements that the client is asking for.
				-	Client may ask something which is either
					-	Technically impossible
					-	Prohibitevely expensive to implement
				-	Eg: Unrealistic low latency
						-	Server is in asia, while client is in america. Where minimum latency is 100ms and clients ask for less than 100ms.

(3)System Constraints
	-	A system constraint is essentially a decision that was already either fully or partially made for us, restricting our degress of freedom.
	-	And it is not always a bad thing.
	-	It makes the jobs easy for designing a system.
	-	System constraints are referred as pillars for software architecture because
		-	They provide us the solid starting point.
		-	The rest of the system needs to be designed around them.
Types of Constraints
	-	(1)Technical Constraints
		-	Eg: using in house servers, rather than using cloud services. Then our architecture will not have cloud technologies.
		-	It may seem they belong to implementation and not to software architecture
		-	In practice, they affect the decisions we make in the design phase and put restrictions on our architecture
	-	(2)Business Constraints
		-	Eg: Very limited budget or stict deadline will have different architecture than unlimited budget and unlimited time.
		-	There are architecture patterns based on suitablity between startups and bigger organizations.
	-	(3)Regulatory/Legal constraints
		-	Eg: In some countries, there is regulation on accessing patient's data.

	-	System Constraints Considerations
		-	(1)Not taking any constraints lightly
			-	There should be distinction between
				-	Real Constraints - Here we can't negotiate
				-	Self-imposed constraints - We can have negotiation with the client.
		-	(2)Use loosly coupled architecture
			-	System should not be tightly coupled to a particular technology.
			-	Usage of different technology/service in future should need minimal changes.


List of Quality Attributes
	-	Performance
	-	Scalability
	-	Availability

Performance Definitions
	-	(1)Response Time
		-	Time between client sending a request and receiving a response.
		-	Response time = processing time + Waiting Time
	-	(2)ThroughPut
		-	Amount of work performed by our system per unit of time.
			-	Measured in task/second.
		-	Amount of data performed by our system per unit of time.
			-	Measured in bits/second, Bytes/second, MBytes/second.

	-	Important Considerations while considering Performance.
	-	1. Measuring Response time Correctly
		-	While measuring response time, waiting time should also be considered, as one request may process fast but more time is spend in waiting. 
	-	2. Response time Distribution
		-	Creating a histogram for number of requests and their response times.
		-	Percentile Definition
			-	The xth Percentile is the value below which x% of the values can be found.
			-	For eg: 20th percentile is having 10 milliseconds response time. Meaning 20 percents of the requests were having response time less than 10 milliseconds.
		-	Tail Latency
			-	The small percentage of response times from a system, that take the longest in comparison to the rest of the values.
			-	Shorter tail is better
		-	Response time Goals Examples
			-	Eg:
				-	30ms at 95th percentile of response time. Meaning 95% of requests should have response time atmost 30ms. Rest 5% can have more response time.
	-	3. Performance Degradation
		-	A point in time where response time increases and throughput decreases significantly.
		-	High-Resource Utilization
			-	High CPU utilization
			-	High memory consumption

Most Important Quality Attributes of large scale systems
(1)Scalability
	-	Load/traffic never stays the same for a given system.
	-	Scalability - The measure of system's ability to handle a growing amount of work, in an easy and cost effective way, by adding resources to the system.

	-	Types of Scalability
		-	(1) Scaling up/Vertical Scalability
			-	Adding resources or upgrading the existing resources on a single computer, to allow our system to handle higher traffic or load.
			-	Pros
				-	Any application can benefit from it 
				-	No code changes required
				-	The migration between different machines is very easy. When traffic is high switch to bigger machine and when traffic is low then switch to lower machine.

			-	Cons
				-	Scope of upgrade is limited
				-	We are locked to a centralized system which cannot provide
					-	High Availability
					-	Fault tolerance
		-	(2) Scaling out/Horizontal Scalability
			-	Adding more resources in a form of new instances running on different machines, to allow our system to handle higher traffic or load.
			-	Pros
				-	No limit on scalability
				-	It's easy to add/remove machines 
				-	If designed correctly we get:
					-	High Availability
					-	Fault tolerance
			-	Cons
				-	Initial code changes may be required.
				-	Increased complexity, coordination overhead.

		-	(3) Team/Organizational Scalability
			-	The measure of a systems ability to handle a growing amount of work(features, testing, bugs, releases), in an easy and cost effective way, by adding resources(more engineers) to the system.
			-	If a codebase is very large and complex, so it is better to break it into separate modules, so that other engineers do not conflict with each other.

			-	Reasons for Productivity Degradation
				-	Many crowded meetings
				-	Code merge conflict
				-	Business Complexity - Longer ramp up time.
				-	Testing is harder and slower
				-	Releases become very risky
(2)Availability
	-	Availability is an important attribute when designing a system
	-	It has the greatest impact on:
		-	Our users
		-	Our business
	-	The fraction of time/probability that our service is operationally functional and accessible to the user.
	-	Formula for Availability
		-	Uptime = Time that our system is operationally functional and accessible to the user
		-	Downtime = Time that our system is unavailable to the user
		-	Availability = Uptime/(Uptime + Downtime)
		-	Alternative way to calculate Availability
			-	(1)MTBF(Mean Time Between Failures)
				-	Represents the average time our system is operational
				-	Useful when:	
					-	Dealing with multiple pieces of hardware
					-	Each component has its own operationsl shelf life
					-	We are not using cloud/third-party API with given uptime and availability
			-	(2)MTTR(Mean Time To Recovery)
				-	Time average it takes us to detect and recover from a failure
				-	Average downtime of our system
		-	Availability = MTBF / (MTBF + MTTR)
		-	In practice, MTTR cannot be zero
		-	Shows that detectability and fast recovery can help us achieve high availability

	-	How much is High Availability?
		-	Users wants 100% availability
		-	On the engineering side:
			-	it is extremely hard to achieve
			-	Leaves no time for maintenance/upgrades
		-	Industry Standard of Availability
			-	No strict definition of what constitutes high availability.
			-	Industry standard set by cloud vendors is typically 99.9% or higher.

	-	Sources of Failures for High Availability
		-	Human Error
			-	Pushing faulty config to production etc.
		-	Software Errors
			-	Long garbage collections
			-	out of memory exceptions etc.
		-	Hardware Failures
			-	Drivers, servers, disk failures etc.

	-	Fault Tolerance
		-	To achieve HA, a system should be fault tolerant
		-	Fault tolerance enables our system to remain operational and available to users despite
			failures within one or multiple of its components.
		-	When failures happen a fault-tolerant system will:
			-	Continue operating at the same/reduced level of performance
			-	Prevent the system from becoming unavailable
		-	Fault tolerance revolves around 3 major tactics
			-	(1)Failure Prevention
				-	To prevent system from going down, eliminate any Single point of failure in our system.
				-	Examples of single point of failure can be:
					-	One server where we're running our application
					-	Storing all our data on the one instance of database that runs on single computer
				-	Best way to eliminate a single point of failure is through REPLICATION and REDUNDANCY.
				-	Types of REDUNDANCY
					-	Spatial Redundancy - Running replicas of our application on different computers
					-	Time Redundancy - Repeating the same operation/request multiple times until we succeed/give up.
				-	Strategies for Redundancy and Replication
					-	Active-Active Architecture
						-	When all replicas serve the requests, so all of them are in sync with each other. And if one of the replica goes down, others can step in. Here same request is not sent to all the replicas.
						-	Advantages
							-	Load is spread among all the replicas. Identical to horizontal scalability.
							-	Allows more traffic.
							-	Better performance.
						-	Disadvantages
							-	All the replicas are taking requests.
							-	Additional coordination required to keep active replicas in sync.
					-	Active-Passive Architecture
						-	When one of the replicas accepts all the requests, and the other replicas takes periodic snapshots of the main replica's state.
						-	Advantages
							-	Implementation is easier
							-	There is clear leader with up-to-date data.
							-	Rest of the replicas are just followers
						-	Disadvantages
							-	Ability to scale our system is lost.
							-	All the requests still go to only one machine.
			-	(2)Failure Dectection and Isolation
				-	To detect failures such as one of the instance of servers not working, we need something for health monitoring system.
				-	False Positive
					-	But the issue might be the network or long garbage collection.
					-	Then the monitoring service is going to have a false positive.
					-	It assumed a healthy host is faulty.
				-	False Negative
					-	The monitoring service shouldn't have false negatives.
					-	False negative mean that:
						-	The servers may have crashed
						-	The monitoring system did not detect that.
				-	Monitoring System Functions
					-	Exchange of messages in the form of pings and heartbeats.
					-	Collect data about the number of errors each host gets per minute.
						-	If the error rate in one of the hosts is high, it can interpret that as failure of the host.
					-	Collect information about time taken for each host to respond.
						-	If the time to respond to requests becomes long, it can decide the host is slow
			-	(3)Recovery
				-	Availability = MTBF / (MTBF + MTTR)
					-	If MTTR is close to 0, then availability becomes close to 100%
				-	Actions after detecting faulty instance/server:
					-	Stop sending traffic/workload to that host.
					-	Restart the host to make the problem go away.
					-	Rollback - going back to a version that was stable and correct.
				-	Rollbacks
					-	Common in databases
					-	rollback to previous stable version


SLA, SLO, SLI
-	SLA(Service Level Agreement)
	-	It is a legal contract that represents our quality service such as:
		-	Availability
		-	Performance
		-	Data durability
		-	Time to respond to success failures
	-	It states the penalties and financial consequences, if we breach the contract
	-	The penalties include:
		-	Full/Partial refunds
		-	Subscription/License extensions
		-	Service credits
	-	SLA and Users
		-	SLA exists for:
			-	External paying users(always)
			-	Free External Users(sometimes)
			-	Internal users within our company(occasionally)
		-	Internal SLAs don't include any penalties
		-	SLA for free external users makes sense if our system has major issues during a free trial of a service
		-	We compensate those users with a trial extension or credits for future.
		-	Companies providing entirely free services don't publish SLA

-	SLO(Service Level Objectives)
	-	Individual goals set for our system.
	-	Each SLO represents a target value/range that our service needs to meet
	-	For example, we can have:
		-	Availability service objective of 3 nines
		-	Response time SLO of less than 100 milliseconds at the 90th percentile.
		-	Issue Resolution Time Objective of between 24 to 48 hours.
	-	SLOs include:
		-	Quality attributes fromt the begining of the design process.
		-	Other objectives of our system.
	-	If a system has an SLA, then each SLO represent an individual agreement within that SLA about a specific metric in the system. So essentially an SLA aggregates all the service level objectives in a single legal document.
	-	Systems that don't have SLA still must have SLOs
	-	If we don't set SLOs then our user won't know what to expect from our system.

-	SLI(Service Level Indicators)
	-	Quantitative measure of our compliance with a service-level objective.
	-	It is the actual numbers:
		-	Measured using montioring service
		-	Calculated from our logs
	-	It can later be compared to our SLOs
	-	Examples: Percentage of user requests receiving a successful response can be used as a SLI for availability.
		-	Later it can be compared to the availability SLO of three nines that we set
